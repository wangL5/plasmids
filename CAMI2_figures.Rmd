---
title: "Preliminary figures from plasmid clasification benchmarking project"
author: "Lu Wang"
output: pdf_document
date: "2025-04-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## CAMI2 benchmarking calculations:
* Accuracy: total number of correct predictions, both positives and negatives, divided by total number of predictions. This predicts overall correctness.
  * (TP + TN) / (TP + TN + FP + FN)
* Precision: accuracy of positive predictions. How many of the predicted positive instances were actually positive?
  * TP / (TP + FP)
* Recall: how well can it identify True Positives out of all the actual positives? True Positive Rate. What proportion of actual plasmids did it detect?
  * TP / (TP + FN)
* Specificity: how well can it identify negative instances out of all actual negative instances?
  * TN / (TN + FP) 
* False Positive Rate: proportion of all actual negatives that were classified incorrectly as positives. Fraction of chromosomes incorrectly classified as plasmids. 
  * FP / (FP + TN)
* F1-Score - harmonic mean of precision and recall → focusing on positives. This is a balanced measure of a model’s performance 
  * (2 x Precision x Recall) / (Precision + Recall)


## Boxplots of all calculated benchmarking parameters for 10 CAMI2 samples
```{r pressure, echo=FALSE}
# Plot boxplots by assembler and classifier
CAMI2_boxplot <- ggplot(CAMI2_benchmarking_bar_plot_df, aes(x = classifier, y = value, fill = assembler)) +
  scale_fill_manual(values=c("orange", "cornflowerblue")) + 
  geom_boxplot(outlier.shape = NA, alpha = 0.8, position = position_dodge(width = 0.8)) +
  facet_wrap(~metric, scales = "free_y", ncol = 2) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Performance Metrics by Classifier and Assembler", x = "", y = "", fill = "",
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold"),
    plot.title = element_text(hjust=0.5)
  )
plot(CAMI2_boxplot)
```
* Comparison of plasmid classifier performance across all 9 classification tools
* Note: platon has a low specificity/high false positive rate for the metaplasmidSPAdes sample set because platon classified almost all metaplasmidSPAdes contigs (across all 10 samples) as plasmid.

## A closer look at the F-1 Score

```{r pressure, echo=FALSE}
f1_score_boxplot <- ggplot(CAMI2_benchmarking_metrics, aes(x = classifier, y = f1_score, fill = assembler)) + geom_boxplot(position = position_dodge(width=0.8)) + 
  scale_fill_manual(values=c("orange", "cornflowerblue")) + 
  theme_minimal(base_size = 14) +
  labs(title = "F1 Score by Classifier and Assembler", x = "", y = "", fill = "",
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold"),
    plot.title = element_text(hjust=0.5),
    panel.grid.major.x = element_blank()
  )
plot(f1_score_boxplot)
```
 * F-1 score for all 9 plasmid classification tools compared against megahit and metaplasmidSPAdes assembly datasets. 
 * No output for plasmidfinder because there were no True Positives predicted for either assembly dataset
 * F-1 score better for all classifiers for metaplasmidSPAdes assembly dataset
 * Plasx with 0.5 cut off had the highest F-1 score


## Precision/Recall Graph for CAMI2 Samples

```{r pressure, echo=FALSE}
library(ggplot2)
library(dplyr)
library(pals)

# precision-recall curve
CAMI2_PR_curve <- ggplot(CAMI2_benchmarking_metrics, aes(x = recall, y = precision, color = classifier)) + scale_color_manual(values=unname(alphabet())) +
  geom_point(alpha = 0.7, size = 2) +
  facet_wrap(~ assembler) +
  labs(
    title = "Precision vs Recall by Assembler and Classifier",
    x = "Recall",
    y = "Precision",
    color = "Classifier"
  ) +
  theme_minimal() +
  theme(
    strip.text = element_text(face = "bold"),
    legend.position = "bottom",
    plot.title = element_text(hjust=0.5)
  )
plot(CAMI2_PR_curve)

```
* Assembly with metaplasmidSPAdes increases precision for almost all plasmid classifiers (with the exception of plasmidfinder). Caveat: this method includes only circular elements.
* With megahit assemblies, all tested plasmid classifiers (except plasx) had precision scores under 0.25. This means that < 25% of predicted plasmids were actually plasmids. 
* The best performing cluster are the plasx/genomad cluster in the metaplasmidSPAdes assembly sample set. But would depend on whether you favor higher recall or higher precision.

### Precision and recall mean for genomad, plasx 0.75, and plasx 0.9 (metaplasmidSPAdes assemblies)
```{r pressure, echo=FALSE}
library(dplyr)

selected_means <- CAMI2_summary_metrics %>%
  filter(classifier %in% c("genomad", "plasx05", "plasx075", "plasx09"),
         assembler %in% c("megahit", "mpspades")) %>%
  select(classifier, assembler, mean_precision, mean_recall)

print(selected_means)
```
plasx is the highest performing plasmid classifier for both megahit and metaplasmidSPAdes assembly datasets. For the CAMI2 marine dataset, the best plasmid classification protocol would be to assemble with metaplasmidSPAdes and then verify results with plasx. 

## Radar plots just for fun

```{r pressure, echo=FALSE}
library(ggradar)
library(dplyr)
library(scales)
library(patchwork)

# Define classifier list and colors
classifiers <- c("dmc", "genomad", "plasx05", "plasx075", "plasx09", "platon")
colors <- c("dmc" = "#F0A0FF",        # amethyst
            "genomad" = "#0075DC",    # blue
            "plasx05" = "#2BCE48",    # green
            "plasx075" = "#FFCC99",   # honeydew
            "plasx09" = "#808080",    # iron
            "platon" = "#94FFB5")     # jade

# New axis labels
new_axis_labels <- c("Accuracy", "Precision", "Recall", "Specificity", "FPR")

# Filter and prepare radar data
radar_data <- CAMI2_benchmarking_metrics %>%
  filter(assembler == "mpspades", classifier %in% classifiers) %>%
  group_by(classifier) %>%
  summarise(across(c(accuracy, precision, recall, specificity, false_positive_rate), mean), .groups = "drop") %>%
  rename_with(~ gsub("mean_", "", .x))  # Optional clean-up

# Rescale data (ggradar expects data between 0 and 1)
#radar_data_rescaled <- radar_data %>%
#  mutate(across(-Classifier, scales::rescale))  # Rescale only numeric columns

# Convert the data to tidy format for ggradar
ggradar_df <- radar_data %>%
  rename(group = classifier)

# Set custom axis labels by changing column names in the data
colnames(ggradar_df)[-1] <- new_axis_labels  # Rename all columns except the first one (group)

# Create a list to store each plot
plots <- list()

# Generate radar plots for each classifier
for (clf in classifiers) {
  clf_data <- ggradar_df %>%
    filter(group == clf)
  
  p <- ggradar(clf_data,
               group.colours = colors[clf],
               axis.label.size = 3,   # font size for axis labels
               grid.label.size = 3,   # font size for grid labels (0, 50, 100)
               group.line.width = 1,  # line width for classifiers
               group.point.size = 3,  # point size at the data locations
               background.circle.colour = "white",  # Background color of the circle
               legend.title = "classifier",
               legend.position = "bottom")   # Position the legend 
  p <- p + ggtitle(clf) + theme(
    plot.title = element_text(hjust=0.5, size=10, face = "bold")
  )
  
  plots[[clf]] <- p  # Store the plot
}

# Combine all plots into a single figure
combined_plot <- plots[["dmc"]] + plots[["genomad"]] + plots[["plasx05"]] +
  plots[["plasx075"]] + plots[["plasx09"]] + plots[["platon"]] +
  plot_layout(ncol = 3)  # Arrange in a 3-column layout

# Show the combined plot
print(combined_plot)

```

 Radar plots of top performing plasmid classifiers (DeepMicroClass (dmc), genomad, plasX (0.5, 0.75, 0.9 confidence score cutoffs), and platon), against metaplasmidSPAdes assemblies


